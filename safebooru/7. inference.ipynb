{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a2c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets \n",
    "import io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8acbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ê²½ë¡œ ë° ì„¤ì • ---\n",
    "data_dir = 'safebooru\\data'\n",
    "model_save_path = os.path.join(data_dir, 'model/best_model.pth')\n",
    "\n",
    "# íƒœê·¸ ì´ë¦„ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ train.csv ì‚¬ìš©\n",
    "train_csv_path = os.path.join(data_dir, 'train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437f6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¤ì • ì™„ë£Œ, ì‚¬ìš© ì¥ì¹˜: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- ì¥ì¹˜ ì„¤ì • ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… ì„¤ì • ì™„ë£Œ, ì‚¬ìš© ì¥ì¹˜: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f1cff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë° 278ê°œ íƒœê·¸ ì´ë¦„ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# íƒœê·¸ ì´ë¦„(í´ë˜ìŠ¤) ëª©ë¡ ë¡œë“œ\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "tag_names = [col for col in train_df.columns if col not in ['id', 'created_at', 'rating', 'score', 'sample_url', 'sample_width', 'sample_height', 'preview_url']]\n",
    "num_tags = len(tag_names)\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡° ì •ì˜ ë° ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "model = models.resnet50()\n",
    "model.fc = nn.Linear(model.fc.in_features, num_tags)\n",
    "model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ë° {num_tags}ê°œ íƒœê·¸ ì´ë¦„ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c7027df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¶”ë¡  í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def predict_tags(model, device, transform, tag_names, image_path=None, image_bytes=None, threshold=0.5):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ ì´ë¯¸ì§€ì˜ íƒœê·¸ë¥¼ ì˜ˆì¸¡í•˜ê³ , ì˜ˆì¸¡ëœ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ì™€ PIL ì´ë¯¸ì§€ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if image_path:\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            return f\"ì˜¤ë¥˜: '{image_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\", None\n",
    "    elif image_bytes:\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "    else:\n",
    "        return \"ì˜¤ë¥˜: ì˜ˆì¸¡í•  ì´ë¯¸ì§€ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\", None\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        preds = torch.sigmoid(outputs) > threshold\n",
    "    \n",
    "    predicted_indices = preds[0].nonzero(as_tuple=True)[0]\n",
    "    predicted_tags = [tag_names[i] for i in predicted_indices]\n",
    "    \n",
    "    # ì˜ˆì¸¡ëœ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ê°ì²´ë¥¼ ë°˜í™˜\n",
    "    return predicted_tags, image\n",
    "\n",
    "# ì¶”ë¡ ì— ì‚¬ìš©í•  ì´ë¯¸ì§€ ë³€í™˜ (ìˆ˜ì • ì—†ìŒ)\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "print(\"âœ… ì¶”ë¡  í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a75e243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05901e4074784a20b964cf52da0e9467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='ì´ë¯¸ì§€ ì—…ë¡œë“œ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a10e48c897b407098c316c3bdb83494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ê³¼ ê²°ê³¼ë¥¼ í‘œì‹œí•  ì¶œë ¥ ìœ„ì ¯ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='image/*',\n",
    "    multiple=False,\n",
    "    description='ì´ë¯¸ì§€ ì—…ë¡œë“œ'\n",
    ")\n",
    "out = widgets.Output() # ê²°ê³¼ë¥¼ í‘œì‹œí•  ì „ìš© ê³µê°„\n",
    "\n",
    "# 2. íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ì‹¤í–‰ë  í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
    "def on_upload_change(change):\n",
    "    if not change['new']:\n",
    "        return\n",
    "    \n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        uploaded_file_info = change['owner'].value[0]\n",
    "        image_bytes = uploaded_file_info['content']\n",
    "\n",
    "        # â˜…â˜…â˜… ì˜ˆì¸¡ í•¨ìˆ˜ë¡œë¶€í„° ê²°ê³¼(íƒœê·¸, ì´ë¯¸ì§€)ë¥¼ ë°›ì•„ì˜´ â˜…â˜…â˜…\n",
    "        predicted_tags, image_to_display = predict_tags(\n",
    "            model=model,\n",
    "            device=device,\n",
    "            transform=inference_transform,\n",
    "            tag_names=tag_names,\n",
    "            image_bytes=image_bytes,\n",
    "            threshold=0.5\n",
    "        )\n",
    "\n",
    "        # â˜…â˜…â˜… ë°›ì•„ì˜¨ ê²°ê³¼ë¥¼ ì—¬ê¸°ì„œ ì§ì ‘ ì¶œë ¥ â˜…â˜…â˜…\n",
    "        if image_to_display:\n",
    "            print(\"--- ğŸ–¼ï¸ ì…ë ¥ëœ ì´ë¯¸ì§€ ğŸ–¼ï¸ ---\")\n",
    "            display(image_to_display.resize((224, int(224 * image_to_display.height / image_to_display.width))))\n",
    "        \n",
    "        print(\"\\n--- ğŸš€ ì˜ˆì¸¡ëœ íƒœê·¸ ğŸš€ ---\")\n",
    "        if isinstance(predicted_tags, list) and predicted_tags:\n",
    "            tags_per_line = 5\n",
    "            for i in range(0, len(predicted_tags), tags_per_line):\n",
    "                print(\"  \".join(predicted_tags[i:i+tags_per_line]))\n",
    "        elif isinstance(predicted_tags, list):\n",
    "            print(\"ì˜ˆì¸¡ëœ íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(predicted_tags) # ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥\n",
    "        \n",
    "        with uploader.hold_sync():\n",
    "            uploader.value = ()\n",
    "\n",
    "# 3. ìœ„ì ¯ì˜ ë³€ê²½ì„ ê°ì§€í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "uploader.observe(on_upload_change, names='value')\n",
    "\n",
    "# 4. ì—…ë¡œë“œ ë²„íŠ¼ê³¼ ì¶œë ¥ ì˜ì—­ì„ í•¨ê»˜ í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "display(uploader, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
